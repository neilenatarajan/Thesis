% \begin{savequote}[8cm]
% Alles Gescheite ist schon gedacht worden.\\
% Man muss nur versuchen, es noch einmal zu denken.

% All intelligent thoughts have already been thought;\\
% what is necessary is only to try to think them again.
%   \qauthor{--- Johann Wolfgang von Goethe \cite{von_goethe_wilhelm_1829}}
% \end{savequote}

\chapter{\label{ch:discussion}Discussion}

\minitoc

\section{The Role of AI Systems in Selection: From Decision Support to Selection-Oriented AI}
% Old version:

% In this thesis, we explore the role of AI systems as Decision Support Tools (DSTs) in talent identification. We find that existing AI systems often fail to meet the needs of selection practitioners, particularly for in-process decision-making. In response, we propose a new paradigm, Selection-Oriented AI (SOAI). While present human-centric paradigms see stakeholders as the centres of design efforts, the problem of selecting talent doesn't lend itself to this framing. In addition to the selection organisation, interested in selecting the best cohort they can, and the applicants, interested in being selected, society at large has interest in the outcomes of selection processes. In particular, social values such as fairness, diversity, integrity, justice, etc. should be upheld. In building tools with selection practitioners as the centre of design, we risk neglecting these broader social values. SOAI seeks to address this by centering the design of AI systems around the social values that selection processes should uphold; while this involves designing around the people making selection decisions, it does not end with their satisfaction. Rather, it requires evaluations of the social impact of selection processes and the tools that support them.


% From ChatGPT:

% 1.1 The Role of AI Systems in Talent Identification: From Decision Support to Selection-Oriented AI

% The increasing adoption of artificial intelligence (AI) systems in decision-making processes has brought to light their potential role as Decision Support Tools (DSTs) in talent identification. In this thesis, we investigate the performance and limitations of existing AI systems within the context of talent selection and assessment. Our findings indicate that, while these systems offer considerable advantages in terms of efficiency and scalability, they often fail to meet the nuanced needs of selection practitioners, particularly when it comes to in-process decision-making—those decisions that are made dynamically during the selection process rather than at predefined points. This shortfall necessitates a new approach to the design and deployment of AI in this domain.


\subsection{Current Challenges in AI for Selection}
AI tools have long been posed as both replacements and support systems for decision-makers both without and within selection processes \cite{barocas_big_2016,jacobs_how_2021,hildebrandt_law_nodate,yarger2020algorithmic,mattu_how_nodate}. Naively, implementations of AI systems supplant human decision-makers, often to disastrous effect \cite{mattu_how_nodate}.
% to-do: can add citations above

More human-centric AI systems, e.g., explainable AI (xAI), often instead serve as decision support tools (DSTs), and place the stakeholder (the selection practitioner) at the core of the decision-making process. These systems then focus on enhancing the experience of human decision-makers, offering tools that satisfy the subjective desiderata of selection practitioners. \textcite{Lipton} critiques post-hoc notions of explainability on the grounds that, in seeking to satisfy stakeholder desiderata, xAI tools may prove more misleading than insightful. While Chapter \ref{ch:xai} extends this critique to the practice of post-hoc justification more broadly, this human-centric paradigm of development threatens to extend the critique to all such systems.

The problem of selection involves a complex interplay of interests. On the one hand, selection organizations are driven by the need to identify the best possible cohort of candidates, aiming to optimize organizational performance and success. On the other hand, candidates are motivated by the desire to be selected for opportunities that match their potential and aspirations. In practice, these two interests are at odds, and while DSTs might support one or the other, the needs of supporting both decisions outstrips the capacity of any individual DST. % to-do: cite

But beyond these two core stakeholders lies a broader societal interest in the outcomes of selection processes. Society at large has a vested interest in ensuring that these processes uphold essential social values such as fairness, diversity, integrity, and justice. In the case of pro-social programs such as global scholarships who seek for their scholars to do good with their careers, society similarly has an interest in ensuring that the most apt scholars are selected.

By centering AI design solely on the needs either applicants or of decision-makers within organizations, we potentially compromise the integrity of the selection process and fail to address the larger social implications of these selection decisions. E.g., algorithms designed to streamline applicant evaluations may inadvertently reinforce existing biases, thereby undermining efforts to promote diversity and inclusion. Similarly, AI systems may prioritize ease of use and decision-making speed at the expense of fairness and transparency. Thus, there is a need for DSTs that, rather than centring on a group of stakeholders, orients itself around the task of selection itself.

\subsection{Proposing a New Paradigm: Selection-Oriented AI (SOAI)}
In response to these challenges, this thesis proposes a novel paradigm: Selection-Oriented AI (SOAI). SOAI reimagines the role of AI systems in talent identification, and advocates for a shift away from the human-centric framework toward a values-centered approach (wherein the design of AI systems is grounded in the social values that selection processes ought to uphold). While selection practitioners remain important users of these systems, they are not the sole focus of design efforts. Instead, SOAI emphasizes the importance of evaluating the broader social impact of AI-driven selection processes, with particular attention to how these processes align with principles of fairness, diversity, and justice. % to-do: cite value-centred design

% This new paradigm recognizes that selection processes do not occur in a vacuum. They have profound societal implications, shaping the distribution of opportunities, resources, and privileges within a community. As such, the design of AI systems for talent selection must go beyond merely satisfying the immediate operational needs of practitioners. SOAI requires an intentional focus on the ethical dimensions of selection, with the explicit goal of ensuring that AI systems support decision-making processes that are not only efficient but also just and inclusive.

% 1.1.4 Evaluating the Social Impact of AI in Selection

% A critical component of SOAI is the development of metrics and frameworks for assessing the social impact of AI-driven selection processes. Traditional evaluation methods for AI systems often focus on accuracy, efficiency, and user satisfaction. However, in the context of talent identification, these metrics are insufficient. SOAI demands a broader evaluation framework that incorporates the ethical, social, and legal consequences of using AI in selection. This includes examining the extent to which AI systems promote or hinder diversity, equity, and inclusion, as well as their ability to safeguard against discriminatory practices.

% Such evaluations may involve comprehensive analyses of the outcomes of selection processes, including demographic analysis of selected cohorts, assessments of fairness in candidate evaluations, and longitudinal studies of how AI-driven decisions impact individual careers and organizational cultures. By adopting these evaluative criteria, SOAI seeks to ensure that AI systems are designed not only to assist in decision-making but to do so in ways that advance the societal values that selection processes are meant to uphold.

% 1.1.5 Conclusion: Toward a Socially Responsible AI in Talent Identification

% In conclusion, the shift toward Selection-Oriented AI represents a necessary evolution in the use of AI systems in talent identification. By prioritizing the social values that selection processes ought to reflect, SOAI challenges the current practitioner-centered approach and introduces a new standard for evaluating the success of AI in decision support. As this thesis will demonstrate, the implementation of SOAI can provide a path forward in creating AI systems that not only assist in the identification of talent but also ensure that the processes by which talent is selected are fair, just, and inclusive. In the following chapters, we will explore the design principles, implementation strategies, and evaluation frameworks necessary to bring SOAI into practice, and examine the broader implications of this paradigm for the future of AI in selection processes.

% \section{The Challenges of SOAI}
% to-do...

\section{Design Recommendations for SOAI Designers}
\subsection{Design for Specific Social Values}
While we wish to design to support all social values in the selection process, Chapter \ref{ch:diversity} demonstrates the difficulty of unpacking the social value of diversity, and we find success instead focusing on smaller component values that comprise diversity. We suggest this generalises to SOAI practices in general. Rather than designing around myriad values, only to find conflicting design implications of these disparate values, designers seeking to support social values in selection processes should focus on specific social values worthy of consideration.

\subsection{Identify Decision Points with the Decision Matrix}
In Chapter \ref{ch:context}, we conceive of selection as a series of decisions. We introduce the Decision Matrix framework to categorise the many decision points that selection practitioners face according to their two most germane axes: the stakes of the decision and its stage in selection. This framework allows designers to evaluate the suitability of AI systems as DSTs for groups of related decision points by determining desired properties for quadrants of the Decision Matrix, then designing for and evaluating those properties. We recommend that designers use the Decision Matrix to identify the decision points relevant to their context and evaluate the suitability of AI systems as DSTs for those points, but to be cautious, as the Decision Matrix framework provides a necessary, but perhaps not sufficient, set of properties. 

\subsection{Balance Quantitative and Qualitative Information in Presentation}
Human decision-makers often desire both a qualitative understanding of applicants and quantitative metrics to compare them. In Chapters \ref{ch:xai} and \ref{ch:diversity}, we find that selection practitioners from programs A and B seek to make decisions informed by both kinds of information; despite this, the desired balance between these modes of information varies based both on practitioner and type of decision. When quantitative information is neglected, practitioners are forced to make decisions on a case-by-case basis without important numerical context comparing applicants to a larger group; when qualitative information is neglected, practitioners are unable to consider applicants holistically. Developers following SOAI should consider the balance between quantitative and qualitative information in their systems, and design their systems to provide both when necessary.

\subsection{Evaluate Real Change in Addition to Subjective Satisfaction}
\textcite{Lipton} critiques explainable AI (xAI) systems on the grounds that they risk satisfying the subjective desires of the users while failing to improve objective outcomes. In Chapter \ref{ch:xai}, we confirm that this critique applies to some post-hoc justifications of model recommendations, as the justifications were found to yield an unwarranted increase in trust in the human decision-makers. Thus, it is important to define and evaluate measures of the social values that DSTs intend to support; when evaluating these DSTs, they should not be evaluated human-centrically (i.e., according to their users' satisfaction), but should instead be evaluated on whether their employment improves social outcomes.

\section{Limitations of SOAI and Possible Solutions}
While quantitative analyses were performed on a variety of participants from program applicants to Prolific members, our qualitative analyses were limited to a small number of selection practitioners from only two programs. While these programs are leaders in the global talent selection context, findings applied to these two programs may not apply directly to other programs. Additionally, while SOAI is likely applicable to related selection contexts such as university selection or job hiring, further research is needed to explore the limits of its generalisability.

We deliberately do not engage applicants in our process. In general, \textcite{Boaz_Hanney_Borst_O’Shea_Kok_2018} contend that human-centred design should consider the positions of all stakeholders. More specifically, \textcite{venn-wycherley_realities_2024} argue that human-centred research in a classroom setting should consider both educators and students. Unlike other scenarios, though, applicant and selection practitioner organisation incentives conflict; and while most HCI contexts would see a need to balance these groups' needs in designing for the space, we conclude that the social aims of the selection problem itself supersede both groups. As selection practitioners most often find themselves aligned to these social aims, we focus on them. Future work should seek to engage applicants in this context. That said, work exploring the perspectives of applicants should consider first the value and ultimate aim of selection. 

% ChatGPT wrote:

% 1.1.6 Inherent Limitations of SOAI: The Exclusion of Applicants in the Design Process

% A deliberate choice in the design of Selection-Oriented AI (SOAI) is the exclusion of applicants from direct engagement during the development of AI systems for talent identification. While human-centered design frameworks, as noted by Boaz et al. (2018), typically emphasize the importance of considering the positions of all stakeholders, SOAI departs from this approach by narrowing its focus. In traditional human-centered research, particularly in settings such as education, the needs and perspectives of multiple groups—educators and students, for example—are carefully balanced in system design (Venn-Wycherley, 2024). However, in the context of selection processes, the interests of applicants and selection practitioners often diverge. This divergence presents a fundamental challenge that complicates the direct inclusion of applicants in the design of AI systems.

% In scenarios outside the selection context, human-computer interaction (HCI) research has generally sought to harmonize the conflicting needs of different user groups through participatory design. Yet, in the case of talent identification, the very nature of the selection process introduces a conflict of incentives between applicants and the selection organization. Applicants are primarily motivated by the desire to be chosen, while selection organizations, guided by practitioners, seek to optimize the quality of the selected cohort. This inherent misalignment of objectives raises significant concerns about how to balance the needs of both groups without compromising the overarching social values that SOAI seeks to uphold.

% Our central argument is that the broader social aims of the selection process—such as ensuring fairness, diversity, and societal integrity—ultimately supersede the immediate interests of both applicants and practitioners. These social objectives, which include promoting equity and justice in the distribution of opportunities, are fundamental to the design of SOAI. As selection practitioners are often more closely aligned with these social aims, we focus our design efforts around their needs, positioning them as the primary users of the AI systems we develop.

% However, this decision introduces a notable limitation in the SOAI framework: the exclusion of the applicant’s perspective from the system design process. While this exclusion is justified by the need to prioritize social outcomes, it remains a potential weakness. Future work should address this gap by exploring ways to incorporate applicants’ viewpoints without compromising the primary focus on social values. Such research could benefit from first reconsidering the ultimate aim of selection and how the perspectives of applicants can be integrated in a manner that reinforces, rather than detracts from, the social goals of fairness and justice.

Much of our work depends on the contested assumption that global selection processes further societal interests, and that thus supporting the selection process improves social outcomes. \textcite{Warikoo_2019} critiques diversity in elite institutions on the grounds that it merely serves to maintain the status quo. We have contended in Chapter \ref{ch:diversity} that, due to the global talent search's broad reach and engagement with people from a truly diverse set of backgrounds, this critique does not apply here. If it does apply here, the implications for SOAI would be dire. Future work should explore the relationship between selection processes and social outcomes, particularly in the context of diversity.

\section{Conclusion}
In this thesis, we pioneer a new paradigm of AI design for selection processes, Selection-Oriented AI (SOAI). Chapters \ref{ch:xai} and \ref{ch:genai} find that existing AI systems often fail to meet the needs of selection practitioners, particularly for in-process decision-making. In response, we propose a new paradigm, SOAI, which seeks to centre the design of AI DSTs not around the selection practitioners but around the social aims of selection they seek to practice. Chapters \ref{ch:diversity} and \ref{ch:spf} apply SOAI principles to design DSTs to support considerations of diversity in selection; we implement a prototype designed to satisfy selection practitioner desires and find that it improves both diversity and performance outcomes in selection. We then provide a set of design recommendations for SOAI designers, including focusing on specific social values, identifying decision points with the Decision Matrix, balancing quantitative and qualitative information, and evaluating real change in addition to subjective satisfaction. We conclude with a call for more selection-oriented work, applying data-driven support to this difficult and sensitive problem.